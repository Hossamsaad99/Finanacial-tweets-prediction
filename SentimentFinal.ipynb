{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis For Stock Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "''' install required libraries '''\n",
    "\n",
    "# !pip install textblob\n",
    "# !pip install nltk\n",
    "# !pip install wordcloud\n",
    "# !pip install tweepy\n",
    "# !pip install langdetect\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import pandas as pd\n",
    "import re ,string, csv\n",
    "\n",
    "# import tweepy # to access tweet API\n",
    "# from tweepy import OAuthHandler # for Authentication\n",
    "\n",
    "from textblob import TextBlob #for Valance of Sentence(polarity)\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "# nltk.download('all') # Installing All from NLTK library\n",
    "from nltk.corpus import stopwords # For Removing Stop words like < the , an , is ,..etc >\n",
    "n_words= stopwords.words('english') #specify english stop words only\n",
    "n_words.append(\"rt\") #append rt for stop word dictionary\n",
    "\n",
    "from nltk.tokenize import word_tokenize # for Tokenizing the sentnces as tokens\n",
    "from nltk.stem.porter import PorterStemmer # converting words to their root forms ,speed and simplicity\n",
    "porter = PorterStemmer() #Create stemmer obejct\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer # also converting words to their actual root forms(noun , verb ,aobjective) ,but it slow\n",
    "lemmatizer = WordNetLemmatizer() #Create lemmatizer obejct\n",
    "\n",
    "from wordcloud import WordCloud,STOPWORDS #Look at Words with highest Frequency for expression\n",
    "\n",
    "from langdetect import detect_langs # Detect language for each tweets \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from nltk import ngrams\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 731: expected 8 fields, saw 13\\nSkipping line 2836: expected 8 fields, saw 15\\nSkipping line 3058: expected 8 fields, saw 12\\nSkipping line 3113: expected 8 fields, saw 12\\nSkipping line 3194: expected 8 fields, saw 17\\nSkipping line 3205: expected 8 fields, saw 17\\nSkipping line 3255: expected 8 fields, saw 17\\nSkipping line 3520: expected 8 fields, saw 17\\nSkipping line 4078: expected 8 fields, saw 17\\nSkipping line 4087: expected 8 fields, saw 17\\nSkipping line 4088: expected 8 fields, saw 17\\nSkipping line 4499: expected 8 fields, saw 12\\n'\n"
     ]
    }
   ],
   "source": [
    "# Reading Datasets\n",
    "stocks=pd.read_csv('C:/Users/user/Desktop/Sentiment/stocks_cleaned.csv')\n",
    "Data=pd.read_csv('C:/Users/user/Desktop/Sentiment/stockerbot-export.csv',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>symbols</th>\n",
       "      <th>company_names</th>\n",
       "      <th>url</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1019696670777503700</td>\n",
       "      <td>VIDEO: “I was in my office. I was minding my o...</td>\n",
       "      <td>Wed Jul 18 21:33:26 +0000 2018</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>GS</td>\n",
       "      <td>The Goldman Sachs</td>\n",
       "      <td>https://twitter.com/i/web/status/1019696670777...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1019709091038548000</td>\n",
       "      <td>The price of lumber $LB_F is down 22% since hi...</td>\n",
       "      <td>Wed Jul 18 22:22:47 +0000 2018</td>\n",
       "      <td>StockTwits</td>\n",
       "      <td>M</td>\n",
       "      <td>Macy's</td>\n",
       "      <td>https://twitter.com/i/web/status/1019709091038...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1019711413798035500</td>\n",
       "      <td>Who says the American Dream is dead? https://t...</td>\n",
       "      <td>Wed Jul 18 22:32:01 +0000 2018</td>\n",
       "      <td>TheStreet</td>\n",
       "      <td>AIG</td>\n",
       "      <td>American</td>\n",
       "      <td>https://buff.ly/2L3kmc4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1019716662587740200</td>\n",
       "      <td>Barry Silbert is extremely optimistic on bitco...</td>\n",
       "      <td>Wed Jul 18 22:52:52 +0000 2018</td>\n",
       "      <td>MarketWatch</td>\n",
       "      <td>BTC</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>https://twitter.com/i/web/status/1019716662587...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1019718460287389700</td>\n",
       "      <td>How satellites avoid attacks and space junk wh...</td>\n",
       "      <td>Wed Jul 18 23:00:01 +0000 2018</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>http://on.forbes.com/6013DqDDU</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1019696670777503700  VIDEO: “I was in my office. I was minding my o...   \n",
       "1  1019709091038548000  The price of lumber $LB_F is down 22% since hi...   \n",
       "2  1019711413798035500  Who says the American Dream is dead? https://t...   \n",
       "3  1019716662587740200  Barry Silbert is extremely optimistic on bitco...   \n",
       "4  1019718460287389700  How satellites avoid attacks and space junk wh...   \n",
       "\n",
       "                        timestamp        source symbols      company_names  \\\n",
       "0  Wed Jul 18 21:33:26 +0000 2018  GoldmanSachs      GS  The Goldman Sachs   \n",
       "1  Wed Jul 18 22:22:47 +0000 2018    StockTwits       M             Macy's   \n",
       "2  Wed Jul 18 22:32:01 +0000 2018     TheStreet     AIG           American   \n",
       "3  Wed Jul 18 22:52:52 +0000 2018   MarketWatch     BTC            Bitcoin   \n",
       "4  Wed Jul 18 23:00:01 +0000 2018        Forbes    ORCL             Oracle   \n",
       "\n",
       "                                                 url  verified  \n",
       "0  https://twitter.com/i/web/status/1019696670777...      True  \n",
       "1  https://twitter.com/i/web/status/1019709091038...      True  \n",
       "2                            https://buff.ly/2L3kmc4      True  \n",
       "3  https://twitter.com/i/web/status/1019716662587...      True  \n",
       "4                     http://on.forbes.com/6013DqDDU      True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28264 entries, 0 to 28263\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             28264 non-null  int64 \n",
      " 1   text           28264 non-null  object\n",
      " 2   timestamp      28264 non-null  object\n",
      " 3   source         28264 non-null  object\n",
      " 4   symbols        28264 non-null  object\n",
      " 5   company_names  28263 non-null  object\n",
      " 6   url            21895 non-null  object\n",
      " 7   verified       28264 non-null  bool  \n",
      "dtypes: bool(1), int64(1), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Convert Columns data types '''\n",
    "\n",
    "# stockerbot[\"timestamp\"] = pd.to_datetime(stockerbot[\"timestamp\"])\n",
    "Data[\"text\"] = Data[\"text\"].astype(str)\n",
    "Data[\"url\"] = Data[\"url\"].astype(str)\n",
    "Data[\"company_names\"] = Data[\"company_names\"].astype(\"category\")\n",
    "Data[\"symbols\"] = Data[\"symbols\"].astype(\"category\")\n",
    "Data[\"source\"] = Data[\"source\"].astype(\"category\")\n",
    "Data=Data.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28264 entries, 0 to 28263\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   text           28264 non-null  object  \n",
      " 1   timestamp      28264 non-null  object  \n",
      " 2   source         28264 non-null  category\n",
      " 3   symbols        28264 non-null  category\n",
      " 4   company_names  28263 non-null  category\n",
      " 5   url            28264 non-null  object  \n",
      " 6   verified       28264 non-null  bool    \n",
      "dtypes: bool(1), category(3), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>symbols</th>\n",
       "      <th>company_names</th>\n",
       "      <th>url</th>\n",
       "      <th>verified</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VIDEO: “I was in my office. I was minding my o...</td>\n",
       "      <td>Wed Jul 18 21:33:26 +0000 2018</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>GS</td>\n",
       "      <td>The Goldman Sachs</td>\n",
       "      <td>https://twitter.com/i/web/status/1019696670777...</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>21:33:26</td>\n",
       "      <td>+0000</td>\n",
       "      <td>2018</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The price of lumber $LB_F is down 22% since hi...</td>\n",
       "      <td>Wed Jul 18 22:22:47 +0000 2018</td>\n",
       "      <td>StockTwits</td>\n",
       "      <td>M</td>\n",
       "      <td>Macy's</td>\n",
       "      <td>https://twitter.com/i/web/status/1019709091038...</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>22:22:47</td>\n",
       "      <td>+0000</td>\n",
       "      <td>2018</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  VIDEO: “I was in my office. I was minding my o...   \n",
       "1  The price of lumber $LB_F is down 22% since hi...   \n",
       "\n",
       "                        timestamp        source symbols      company_names  \\\n",
       "0  Wed Jul 18 21:33:26 +0000 2018  GoldmanSachs      GS  The Goldman Sachs   \n",
       "1  Wed Jul 18 22:22:47 +0000 2018    StockTwits       M             Macy's   \n",
       "\n",
       "                                                 url  verified dayofweek  \\\n",
       "0  https://twitter.com/i/web/status/1019696670777...      True       Wed   \n",
       "1  https://twitter.com/i/web/status/1019709091038...      True       Wed   \n",
       "\n",
       "  month day      time timezone  year hour minute second  \n",
       "0   Jul  18  21:33:26    +0000  2018   21     33     26  \n",
       "1   Jul  18  22:22:47    +0000  2018   22     22     47  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Split Timestamp Column into Dates and times '''\n",
    "\n",
    "Data[['dayofweek','month','day','time','timezone', 'year']] = Data.timestamp.str.split(expand=True)\n",
    "Data[['hour','minute','second']] = Data.time.str.split(':',expand=True)\n",
    "Data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text             False\n",
       "timestamp        False\n",
       "source           False\n",
       "symbols          False\n",
       "company_names     True\n",
       "url              False\n",
       "verified         False\n",
       "dayofweek        False\n",
       "month            False\n",
       "day              False\n",
       "time             False\n",
       "timezone         False\n",
       "year             False\n",
       "hour             False\n",
       "minute           False\n",
       "second           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Check for null values '''\n",
    "Data.isnull().any() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a null values in Company Names Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null :1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>symbols</th>\n",
       "      <th>company_names</th>\n",
       "      <th>url</th>\n",
       "      <th>verified</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3369</th>\n",
       "      <td>When you try to gauge sentiment on a $ticker b...</td>\n",
       "      <td>Thu Jul 12 14:28:55 +0000 2018</td>\n",
       "      <td>provotrout</td>\n",
       "      <td>ticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "      <td>Thu</td>\n",
       "      <td>Jul</td>\n",
       "      <td>12</td>\n",
       "      <td>14:28:55</td>\n",
       "      <td>+0000</td>\n",
       "      <td>2018</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "3369  When you try to gauge sentiment on a $ticker b...   \n",
       "\n",
       "                           timestamp      source symbols company_names  url  \\\n",
       "3369  Thu Jul 12 14:28:55 +0000 2018  provotrout  ticker           NaN  nan   \n",
       "\n",
       "      verified dayofweek month day      time timezone  year hour minute second  \n",
       "3369     False       Thu   Jul  12  14:28:55    +0000  2018   14     28     55  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Check for null values in Company names columns '''\n",
    "\n",
    "print(f'null :{Data.company_names.isnull().sum()}')\n",
    "Data[Data['company_names'].isnull()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only One Null Values , so not important for us to delete or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most sources:\n",
      "bibeypost_stock    990\n",
      "whatsonthorold2    963\n",
      "mmahotstuff1       899\n",
      "reurope_stock      668\n",
      "MareaInformativ    640\n",
      "optioncharts       614\n",
      "ConsumerFeed       411\n",
      "dispatchtribune    375\n",
      "EnterpriseLeade    368\n",
      "TranscriptDaily    359\n",
      "Name: source, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a look at 10 Largest Source \n",
    "total_sources = Data[\"source\"].value_counts()\n",
    "print(f'Most sources:\\n{total_sources.nlargest(10)}')\n",
    "plt.figure(figsize=(15,5))\n",
    "# total_sources.head(50).sort_values(ascending=False).plot(kind='bar') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most companies:\n",
      "NFLX    101\n",
      "MOMO    100\n",
      "HON     100\n",
      "AMAT    100\n",
      "GPS     100\n",
      "ES      100\n",
      "MTB     100\n",
      "GRPN     99\n",
      "MAS      99\n",
      "ESS      99\n",
      "Name: symbols, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a look at 10 Largest symbols \n",
    "total_companies = Data[\"symbols\"].value_counts()\n",
    "print(f'Most companies:\\n{total_companies.nlargest(10)}')\n",
    "plt.figure(figsize=(15,5))\n",
    "# total_companies.head(50).sort_values(ascending=False).plot(kind='bar') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28264"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Unwanted Some Text \n",
    "Data=Data[Data[\"text\"]!='btc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Clean Function to fix text\n",
    "def Clean(text):\n",
    "\n",
    "  # Frist converting all letters to lower case\n",
    "  text= text.lower()\n",
    "  \n",
    "  # removing unwanted digits ,special chracters from the text\n",
    "  text= ' '.join(re.sub(\"(@[A-Za-z0-9]+)\", \" \", text).split()) #tags\n",
    "  text= ' '.join(re.sub(\"^@?(\\w){1,15}$\", \" \", text).split())\n",
    "    \n",
    "  text= ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", text).split())   #Links\n",
    "  text= ' '.join(re.sub(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\" \", text).split()) \n",
    "  text= ' '.join(re.sub(r'http\\S+', '',text).split())\n",
    "  \n",
    "  \n",
    "  text= ' '.join(re.sub(r'www\\S+', '',text).split())\n",
    "  text= ' '.join(re.sub(\"\\s+\", \" \",text).split()) #Extrem white Space\n",
    "  text= ' '.join(re.sub(\"[^-9A-Za-z ]\", \"\" ,text).split()) #digits \n",
    "  text= ' '.join(re.sub('-', ' ', text).split()) \n",
    "  text= ' '.join(re.sub('_', ' ', text).split()) #underscore \n",
    "  \n",
    "  # Display available PUNCTUATION for examples\n",
    "  #for c in string.punctuation:\n",
    "       #print(f\"[{c}]\")\n",
    "  \n",
    "  # removing stopwards and numbers from STRING library\n",
    "  table= str.maketrans('', '', string.punctuation+string.digits)\n",
    "  text = text.translate(table)\n",
    "  \n",
    "  # Split Sentence as tokens words \n",
    "  tokens = word_tokenize(text)\n",
    "  \n",
    "  # converting words to their root forms by STEMMING THE WORDS \n",
    "#   stemmed1 = [lemmatizer.lemmatize(word) for word in tokens] #Covert words to their actual root\n",
    "  stemmed2 = [porter.stem(word) for word in tokens] # Covert words to their rootbut not actual\n",
    "  \n",
    "  # Delete each stop words from English stop words\n",
    "#   words = [w for w in stemmed1 if not w in n_words] #n_words contains English stop words\n",
    "  words = [w for w in stemmed2 if not w in n_words] #n_words contains English stop words\n",
    "\n",
    "  text  = ' '.join(words)\n",
    "    \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        VIDEO: “I was in my office. I was minding my o...\n",
       "1        The price of lumber $LB_F is down 22% since hi...\n",
       "2        Who says the American Dream is dead? https://t...\n",
       "3        Barry Silbert is extremely optimistic on bitco...\n",
       "4        How satellites avoid attacks and space junk wh...\n",
       "                               ...                        \n",
       "28259           $FB : 29234a9c-7f08-4d5a-985f-cb1a5554ecf9\n",
       "28260    【仮想通貨】ビットコインの価格上昇、８０万円台回復　約１カ月半ぶり　　　　　　$BTC ht...\n",
       "28261    RT @invest_in_hd: 'Nuff said!  $TEL #telcoin #...\n",
       "28262    【仮想通貨】ビットコインの価格上昇、８０万円台回復　約１カ月半ぶり　　　　　　$BTC ht...\n",
       "28263    Stellar $XLM price: $0.297852 Binance registra...\n",
       "Name: text, Length: 28264, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Before Pre-processing\n",
    "Data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete unwanted source form our text \n",
    "Data=Data[Data[\"source\"] != \"test5f1798\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply Clean Funsction to our Text\n",
    "Data.text=[Clean(x) for x in Data.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        video wa offic wa mind busi david solomon tell...\n",
       "1        price lumber lbf sinc hit ytd high maci turnar...\n",
       "2                                  say american dream dead\n",
       "3        barri silbert extrem optimist bitcoin predict ...\n",
       "4        satellit avoid attack space junk circl earth paid\n",
       "                               ...                        \n",
       "28258    new exchang telcoin mid august im glad tel big...\n",
       "28260                                                  btc\n",
       "28261    inhd nuff said tel telcoin telfam crypto block...\n",
       "28262                                                  btc\n",
       "28263     stellar xlm price binanc registr open limit time\n",
       "Name: text, Length: 28239, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Unwanted Some Text \n",
    "Data=Data[Data[\"text\"]!='btc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        video wa offic wa mind busi david solomon tell...\n",
       "1        price lumber lbf sinc hit ytd high maci turnar...\n",
       "2                                  say american dream dead\n",
       "3        barri silbert extrem optimist bitcoin predict ...\n",
       "4        satellit avoid attack space junk circl earth paid\n",
       "                               ...                        \n",
       "28256    exxon onc perfect machin run dri wall street j...\n",
       "28257                         fallen hero today btc action\n",
       "28258    new exchang telcoin mid august im glad tel big...\n",
       "28261    inhd nuff said tel telcoin telfam crypto block...\n",
       "28263     stellar xlm price binanc registr open limit time\n",
       "Name: text, Length: 28225, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text after Pre-processing\n",
    "Data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Detect Emotions for each text Form TextBlob Library '''\n",
    "\n",
    "detectEmotion=[]\n",
    "detectPolarity=[]\n",
    "\n",
    "for txt in Data.text:\n",
    "    \n",
    "    analysis=TextBlob(txt)\n",
    "    Polarity=analysis.sentiment.polarity\n",
    "    \n",
    "    if Polarity  <0:\n",
    "        emotion='2'  #Negative\n",
    "    elif Polarity>0: \n",
    "        emotion='1'  #Positive\n",
    "    else:\n",
    "        emotion='0'  #Neutral\n",
    "        \n",
    "    detectEmotion.append(emotion)\n",
    "    detectPolarity.append(Polarity)\n",
    "    \n",
    "# detectEmotion=pd.DataFrame()\n",
    "\n",
    "Data['Polarity']=detectPolarity\n",
    "Data['Emotion'] =detectEmotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>source</th>\n",
       "      <th>symbols</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>language</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video wa offic wa mind busi david solomon tell...</td>\n",
       "      <td>https://twitter.com/i/web/status/1019696670777...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>Wed</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>GS</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>price lumber lbf sinc hit ytd high maci turnar...</td>\n",
       "      <td>https://twitter.com/i/web/status/1019709091038...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>Wed</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>StockTwits</td>\n",
       "      <td>M</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say american dream dead</td>\n",
       "      <td>https://buff.ly/2L3kmc4</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>Wed</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>01</td>\n",
       "      <td>TheStreet</td>\n",
       "      <td>AIG</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  video wa offic wa mind busi david solomon tell...   \n",
       "1  price lumber lbf sinc hit ytd high maci turnar...   \n",
       "2                            say american dream dead   \n",
       "\n",
       "                                                 url  year month day  \\\n",
       "0  https://twitter.com/i/web/status/1019696670777...  2018   Jul  18   \n",
       "1  https://twitter.com/i/web/status/1019709091038...  2018   Jul  18   \n",
       "2                            https://buff.ly/2L3kmc4  2018   Jul  18   \n",
       "\n",
       "  dayofweek hour minute second        source symbols  Polarity Emotion  \\\n",
       "0       Wed   21     33     26  GoldmanSachs      GS      0.00       0   \n",
       "1       Wed   22     22     47    StockTwits       M      0.16       1   \n",
       "2       Wed   22     32     01     TheStreet     AIG     -0.10       2   \n",
       "\n",
       "  language  verified  \n",
       "0       en      True  \n",
       "1       en      True  \n",
       "2       en      True  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data  = Data[Data['verified'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "28207\n"
     ]
    }
   ],
   "source": [
    "#check for valid string only to detect languages\n",
    "\n",
    "TextValid=[]\n",
    "\n",
    "for i in range(len(Data)):\n",
    "    TextValid.append(bool(re.match('^(?=.*[a-zA-Z])', Data.iloc[i,0])))\n",
    "    \n",
    "Data['valid']=TextValid\n",
    "print(len(Data[Data['valid']==False]))\n",
    "print(len(Data[Data['valid']==True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid string only\n",
    "\n",
    "Data=Data[Data['valid']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Detect languages for each text to filter into specific Lang'''\n",
    "\n",
    "languages = []\n",
    "\n",
    "# Loop over the sentences in the data and detect their language\n",
    "for row in range(len(Data)):\n",
    "    languages.append(detect_langs(Data.iloc[row, 0]))\n",
    "    \n",
    "# print('The detected languages are: ', languages) >>> ['en':'N']\n",
    "languages = [str(lang).split(':')[0][1:] for lang in languages] \n",
    "\n",
    "# Assign the list to a new feature \n",
    "Data['language'] = languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    19388\n",
       "ca     1519\n",
       "it     1155\n",
       "fr     1123\n",
       "ro      839\n",
       "sv      655\n",
       "nl      511\n",
       "da      404\n",
       "no      331\n",
       "es      325\n",
       "cy      282\n",
       "af      236\n",
       "so      200\n",
       "id      168\n",
       "pt      149\n",
       "sl      137\n",
       "et      112\n",
       "tl      105\n",
       "sw       75\n",
       "pl       64\n",
       "de       60\n",
       "hr       59\n",
       "sq       59\n",
       "fi       57\n",
       "sk       41\n",
       "hu       34\n",
       "cs       29\n",
       "tr       26\n",
       "lt       25\n",
       "vi       22\n",
       "lv       17\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at Lang detected from our text\n",
    "\n",
    "Data['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We Only want to deal with english text for now , so we will filter data for EN Only\n",
    "\n",
    "Data=Data[Data['language']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>source</th>\n",
       "      <th>symbols</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>language</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video wa offic wa mind busi david solomon tell...</td>\n",
       "      <td>https://twitter.com/i/web/status/1019696670777...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>Wed</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>GS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>price lumber lbf sinc hit ytd high maci turnar...</td>\n",
       "      <td>https://twitter.com/i/web/status/1019709091038...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>Wed</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>StockTwits</td>\n",
       "      <td>M</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say american dream dead</td>\n",
       "      <td>https://buff.ly/2L3kmc4</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>Wed</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>01</td>\n",
       "      <td>TheStreet</td>\n",
       "      <td>AIG</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barri silbert extrem optimist bitcoin predict ...</td>\n",
       "      <td>https://twitter.com/i/web/status/1019716662587...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>Wed</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>MarketWatch</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  video wa offic wa mind busi david solomon tell...   \n",
       "1  price lumber lbf sinc hit ytd high maci turnar...   \n",
       "2                            say american dream dead   \n",
       "3  barri silbert extrem optimist bitcoin predict ...   \n",
       "\n",
       "                                                 url  year month day  \\\n",
       "0  https://twitter.com/i/web/status/1019696670777...  2018   Jul  18   \n",
       "1  https://twitter.com/i/web/status/1019709091038...  2018   Jul  18   \n",
       "2                            https://buff.ly/2L3kmc4  2018   Jul  18   \n",
       "3  https://twitter.com/i/web/status/1019716662587...  2018   Jul  18   \n",
       "\n",
       "  dayofweek hour minute second        source symbols  Polarity Emotion  \\\n",
       "0       Wed   21     33     26  GoldmanSachs      GS  0.000000       0   \n",
       "1       Wed   22     22     47    StockTwits       M  0.160000       1   \n",
       "2       Wed   22     32     01     TheStreet     AIG -0.100000       2   \n",
       "3       Wed   22     52     52   MarketWatch     BTC  0.136364       1   \n",
       "\n",
       "  language  verified  \n",
       "0       en      True  \n",
       "1       en      True  \n",
       "2       en      True  \n",
       "3       en      True  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data=Data[['text','url','year','month','day','dayofweek','hour','minute','second','source','symbols','Polarity','Emotion','language','verified']]\n",
    "Data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26452</th>\n",
       "      <td>kind fun watch race trillion market cap ani in...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26507</th>\n",
       "      <td>appl ha join suppli invest almost next four ye...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26553</th>\n",
       "      <td>end day corn introduc gorilla glass intel turn...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26747</th>\n",
       "      <td>wa think icahn letter say appl wa worth sold h...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26789</th>\n",
       "      <td>extern true tone display featur onli work macb...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26797</th>\n",
       "      <td>motola agre work thi space use aw isnt reliabl...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27005</th>\n",
       "      <td>googl blast eu commiss rule question whi refus...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27089</th>\n",
       "      <td>instant appl unlock cent iphon gs c unlockfus ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27241</th>\n",
       "      <td>corn debut gorilla glass unpreced multi drop p...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27650</th>\n",
       "      <td>aapl appl inc grow earn annual next year marke...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27680</th>\n",
       "      <td>appl roll third public beta io tvo aapl</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27696</th>\n",
       "      <td>actual dan block coupl year ago becaus told hi...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27698</th>\n",
       "      <td>watch show futur time go chart thank aapl ipad...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27724</th>\n",
       "      <td>watch show futur time go chart thank aapl ipad...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27883</th>\n",
       "      <td>corn unveil next gen super durabl gorilla glas...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27885</th>\n",
       "      <td>wa think icahn letter say appl wa worth sold h...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27887</th>\n",
       "      <td>aapl long trend chart</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28093</th>\n",
       "      <td>decluttr survey us singl would prefer date iph...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jul</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  year month day  \\\n",
       "26452  kind fun watch race trillion market cap ani in...  2018   Jul  18   \n",
       "26507  appl ha join suppli invest almost next four ye...  2018   Jul  18   \n",
       "26553  end day corn introduc gorilla glass intel turn...  2018   Jul  18   \n",
       "26747  wa think icahn letter say appl wa worth sold h...  2018   Jul  18   \n",
       "26789  extern true tone display featur onli work macb...  2018   Jul  18   \n",
       "26797  motola agre work thi space use aw isnt reliabl...  2018   Jul  18   \n",
       "27005  googl blast eu commiss rule question whi refus...  2018   Jul  18   \n",
       "27089  instant appl unlock cent iphon gs c unlockfus ...  2018   Jul  18   \n",
       "27241  corn debut gorilla glass unpreced multi drop p...  2018   Jul  18   \n",
       "27650  aapl appl inc grow earn annual next year marke...  2018   Jul  18   \n",
       "27680            appl roll third public beta io tvo aapl  2018   Jul  18   \n",
       "27696  actual dan block coupl year ago becaus told hi...  2018   Jul  18   \n",
       "27698  watch show futur time go chart thank aapl ipad...  2018   Jul  18   \n",
       "27724  watch show futur time go chart thank aapl ipad...  2018   Jul  18   \n",
       "27883  corn unveil next gen super durabl gorilla glas...  2018   Jul  18   \n",
       "27885  wa think icahn letter say appl wa worth sold h...  2018   Jul  18   \n",
       "27887                              aapl long trend chart  2018   Jul  18   \n",
       "28093  decluttr survey us singl would prefer date iph...  2018   Jul  18   \n",
       "\n",
       "       Polarity Emotion  \n",
       "26452  0.450000       1  \n",
       "26507  0.183333       1  \n",
       "26553  0.000000       0  \n",
       "26747  0.300000       1  \n",
       "26789  0.175000       1  \n",
       "26797  0.800000       1  \n",
       "27005  0.000000       0  \n",
       "27089  0.000000       0  \n",
       "27241  0.000000       0  \n",
       "27650  0.000000       0  \n",
       "27680  0.000000       0  \n",
       "27696  0.000000       0  \n",
       "27698  0.000000       0  \n",
       "27724  0.000000       0  \n",
       "27883  0.166667       1  \n",
       "27885  0.300000       1  \n",
       "27887 -0.050000       2  \n",
       "28093  0.000000       0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple=Data[['text','year','month','day','Polarity','Emotion']][Data.symbols=='AAPL']\n",
    "apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Percentage Positive: 0.3888888888888889\n",
      " Percentage Negetive: 0.05555555555555555\n",
      " Percentage Neutral : 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Percentage of each Emotions for apple only\n",
    "\n",
    "app_neutral   = apple['text'][ apple['Emotion'] == '0']\n",
    "app_positive = apple['text'][ apple['Emotion'] == '1']\n",
    "app_negative = apple['text'][ apple['Emotion'] == '2']\n",
    "\n",
    "print(f' Percentage Positive: {len(app_positive)/len(apple)}\\n Percentage Negetive: {len(app_negative)/len(apple)}\\n Percentage Neutral : {len(app_neutral)/len(apple)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below function will create a word cloud\n",
    "\n",
    "def wordcloud_draw(data, color = 'black'):\n",
    "    words = ' '.join(data)\n",
    "    cleaned_word = \" \".join([word for word in words.split()\n",
    "                            if 'http' not in word  # double check for nay links\n",
    "                                and not word.startswith('#')  # removing hash tags\n",
    "                                and word != 'rt'  \n",
    "                            ])\n",
    "    wordcloud = WordCloud(stopwords=STOPWORDS, # using stopwords provided by Word cloud its optional since we already removed stopwords :)\n",
    "                      background_color=color,\n",
    "                      width=2500,\n",
    "                      height=2000\n",
    "                     ).generate(cleaned_word)\n",
    "    # using matplotlib to display the images in notebook itself.\n",
    "    plt.figure(1,figsize=(13, 13))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Most Positive words Frequency\")\n",
    "# wordcloud_draw(app_positive, 'white')\n",
    "# print(\"Most Negative words Frequency\")\n",
    "# wordcloud_draw(app_negative)\n",
    "# print(\"Most Neutral words Frequency\")\n",
    "# wordcloud_draw(app_neutral, 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Percentage Positive: 0.2599030328037962\n",
      " Percentage Negetive: 0.08087476789766866\n",
      " Percentage Neutral: 0.6592221992985352\n"
     ]
    }
   ],
   "source": [
    "# Percentage of each Emotions overall symbols\n",
    "\n",
    "df_neutral   = Data['text'][ Data['Emotion'] == '0']\n",
    "df_positive  = Data['text'][ Data['Emotion'] == '1']\n",
    "df_negative  = Data['text'][ Data['Emotion'] == '2']\n",
    "\n",
    "\n",
    "print(f' Percentage Positive: {len(df_positive)/len(Data)}\\n Percentage Negetive: {len(df_negative)/len(Data)}\\n Percentage Neutral: {len(df_neutral)/len(Data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Most Positive words Frequency\")\n",
    "# wordcloud_draw(df_positive, 'white')\n",
    "# print(\"Most Negative words Frequency\")\n",
    "# wordcloud_draw(df_negative)\n",
    "# print(\"Most Neutral words Frequency\")\n",
    "# wordcloud_draw(df_neutral, 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataset\n",
    "Data.to_csv(\"MystockData.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NgramModels(Model , txt, n):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(Data['text'], Data['Emotion'], test_size=0.2, random_state=50)\n",
    "    \n",
    "    vect      = CountVectorizer(max_features=1000 , ngram_range=(n,n))\n",
    "    train_vect= vect.fit_transform(x_train)\n",
    "    test_vect = vect.transform(x_test)\n",
    "    \n",
    "    model     = Model\n",
    "    t0        = time.time()\n",
    "    model.fit(train_vect, y_train)\n",
    "    t1        = time.time()\n",
    "    predicted = model.predict(test_vect)\n",
    "    t2        = time.time()\n",
    "    time_train= t1-t0\n",
    "    time_pred = t2-t1\n",
    "    \n",
    "    accuracy  = model.score(train_vect, y_train)\n",
    "    predicted = model.predict(test_vect)\n",
    "    \n",
    "    report = classification_report(y_test, predicted, output_dict=True)\n",
    "    print(\"Models with \" , n , \"-grams :\\n\")\n",
    "    print('********************** \\n')\n",
    "    print(txt)\n",
    "    print(\"Training time: %fs; Prediction time: %fs \\n\" % (time_train, time_pred))\n",
    "    print('Accuracy score train set :', accuracy)\n",
    "    print('Accuracy score test set  :', accuracy_score(y_test, predicted),'\\n')\n",
    "    print('Positive: ', report['1'])\n",
    "    print('Neutral : ', report['0'])\n",
    "    print('Negative: ', report['2'])\n",
    "    print('\\n --------------------------------------------------------------------------------------------------- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_Ngram(n):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(Data['text'], Data['Emotion'], test_size=0.2, random_state=50)\n",
    "    \n",
    "    vect      = CountVectorizer(max_features=1000 , ngram_range=(n,n))\n",
    "    train_vect= vect.fit_transform(x_train)\n",
    "    test_vect = vect.transform(x_test)\n",
    "    \n",
    "    for k in [1,3,5,7,10]:\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=k,algorithm='brute')\n",
    "        t0        = time.time()\n",
    "        model.fit(train_vect, y_train)\n",
    "        t1        = time.time()\n",
    "        predicted = model.predict(test_vect)\n",
    "        t2        = time.time()\n",
    "        time_train= t1-t0\n",
    "        time_pred = t2-t1\n",
    "\n",
    "        accuracy  = model.score(train_vect, y_train)\n",
    "        predicted = model.predict(test_vect)\n",
    "\n",
    "        report = classification_report(y_test, predicted, output_dict=True)\n",
    "\n",
    "        print(\"Models with \" , n , \"-grams :\\n\")\n",
    "        print('********************** \\n')\n",
    "        print(\"Classification Report for k = {} is:\\n\".format(k))\n",
    "        print(\"Training time: %fs ; Prediction time: %fs \\n\" % (time_train, time_pred))\n",
    "        print('Accuracy score train set :', accuracy)\n",
    "        print('Accuracy score test set  :', accuracy_score(y_test, predicted),'\\n')\n",
    "        print('Positive: ', report['1'])\n",
    "        print('Neutral : ', report['0'])\n",
    "        print('Negative: ', report['2'])\n",
    "        print('\\n -------------------------------------------------------------------------------------- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDFModels(Model,txt):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(Data['text'], Data['Emotion'], test_size=0.2, random_state=50)\n",
    "    \n",
    "    vect      = TfidfVectorizer(min_df = 5, max_df =0.8, sublinear_tf = True, use_idf = True)\n",
    "    train_vect= vect.fit_transform(x_train)\n",
    "    test_vect = vect.transform(x_test)\n",
    "    \n",
    "    model     = Model\n",
    "    t0        = time.time()\n",
    "    model.fit(train_vect, y_train)\n",
    "    t1        = time.time()\n",
    "    predicted = model.predict(test_vect)\n",
    "    t2        = time.time()\n",
    "    time_train= t1-t0\n",
    "    time_pred = t2-t1\n",
    "    \n",
    "    accuracy  = model.score(train_vect, y_train)\n",
    "    predicted = model.predict(test_vect)\n",
    "    \n",
    "    report = classification_report(y_test, predicted, output_dict=True)\n",
    "    \n",
    "    print(txt)\n",
    "    print(\"Training time: %fs; Prediction time: %fs \\n\" % (time_train, time_pred))\n",
    "    print('Accuracy score train set :', accuracy)\n",
    "    print('Accuracy score test set  :', accuracy_score(y_test, predicted),'\\n')\n",
    "    print('Positive: ', report['1'])\n",
    "    print('Neutral : ', report['0'])\n",
    "    print('Negative: ', report['2'])\n",
    "    print('\\n -------------------------------------------------------------------------------------- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_TFIDF():\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(Data['text'], Data['Emotion'], test_size=0.2, random_state=50)\n",
    "    \n",
    "    vect      = TfidfVectorizer(min_df = 5, max_df =0.8, sublinear_tf = True, use_idf = True)\n",
    "    train_vect= vect.fit_transform(x_train)\n",
    "    test_vect = vect.transform(x_test)\n",
    "    \n",
    "    for k in [1,3,5,7,10]:\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=k,algorithm='brute')\n",
    "        t0        = time.time()\n",
    "        model.fit(train_vect, y_train)\n",
    "        t1        = time.time()\n",
    "        predicted = model.predict(test_vect)\n",
    "        t2        = time.time()\n",
    "        time_train= t1-t0\n",
    "        time_pred = t2-t1\n",
    "\n",
    "        accuracy  = model.score(train_vect, y_train)\n",
    "        predicted = model.predict(test_vect)\n",
    "\n",
    "        report = classification_report(y_test, predicted, output_dict=True)\n",
    "\n",
    "        print(\"Classification Report for k = {} is:\\n\".format(k))\n",
    "        print(\"Training time: %fs ; Prediction time: %fs \\n\" % (time_train, time_pred))\n",
    "        print('Accuracy score train set :', accuracy)\n",
    "        print('Accuracy score test set  :', accuracy_score(y_test, predicted),'\\n')\n",
    "        print('Positive: ', report['1'])\n",
    "        print('Neutral : ', report['0'])\n",
    "        print('Negative: ', report['2'])\n",
    "        print('\\n -------------------------------------------------------------------------------------- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models with  2 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Logistic Regression Model : \n",
      " \n",
      "Training time: 1.701037s; Prediction time: 0.000000s \n",
      "\n",
      "Accuracy score train set : 0.8079303675048356\n",
      "Accuracy score test set  : 0.8032490974729242 \n",
      "\n",
      "Positive:  {'precision': 0.9135021097046413, 'recall': 0.44777662874870733, 'f1-score': 0.600971547536433, 'support': 967}\n",
      "Neutral :  {'precision': 0.7820940819423369, 'recall': 0.990392006149116, 'f1-score': 0.8740037307105307, 'support': 2602}\n",
      "Negative:  {'precision': 0.963302752293578, 'recall': 0.33980582524271846, 'f1-score': 0.5023923444976076, 'support': 309}\n",
      "\n",
      " --------------------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  3 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Logistic Regression Model : \n",
      " \n",
      "Training time: 1.823998s; Prediction time: 0.000000s \n",
      "\n",
      "Accuracy score train set : 0.7780786589297227\n",
      "Accuracy score test set  : 0.7753996905621454 \n",
      "\n",
      "Positive:  {'precision': 0.9514285714285714, 'recall': 0.344364012409514, 'f1-score': 0.5056947608200455, 'support': 967}\n",
      "Neutral :  {'precision': 0.752541388324136, 'recall': 0.995772482705611, 'f1-score': 0.8572373862696443, 'support': 2602}\n",
      "Negative:  {'precision': 0.9764705882352941, 'recall': 0.2686084142394822, 'f1-score': 0.4213197969543147, 'support': 309}\n",
      "\n",
      " --------------------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  2 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Support Vectoer Classifier Model : \n",
      " \n",
      "Training time: 9.647092s; Prediction time: 0.495999s \n",
      "\n",
      "Accuracy score train set : 0.8073500967117988\n",
      "Accuracy score test set  : 0.8042805569881382 \n",
      "\n",
      "Positive:  {'precision': 0.924892703862661, 'recall': 0.44570837642192346, 'f1-score': 0.6015352407536636, 'support': 967}\n",
      "Neutral :  {'precision': 0.7818181818181819, 'recall': 0.9915449654112222, 'f1-score': 0.8742799051169096, 'support': 2602}\n",
      "Negative:  {'precision': 0.9642857142857143, 'recall': 0.34951456310679613, 'f1-score': 0.5130641330166271, 'support': 309}\n",
      "\n",
      " --------------------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  3 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Support Vectoer Classifier Model : \n",
      " \n",
      "Training time: 4.255566s; Prediction time: 0.690589s \n",
      "\n",
      "Accuracy score train set : 0.7780786589297227\n",
      "Accuracy score test set  : 0.7774626095925735 \n",
      "\n",
      "Positive:  {'precision': 0.9707602339181286, 'recall': 0.34332988624612204, 'f1-score': 0.507257448433919, 'support': 967}\n",
      "Neutral :  {'precision': 0.7529718759060597, 'recall': 0.9980784012298232, 'f1-score': 0.8583705172698728, 'support': 2602}\n",
      "Negative:  {'precision': 0.9885057471264368, 'recall': 0.2783171521035599, 'f1-score': 0.4343434343434344, 'support': 309}\n",
      "\n",
      " --------------------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  2 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Decision Tree Classifier Model : \n",
      " \n",
      "Training time: 0.349916s; Prediction time: 0.008175s \n",
      "\n",
      "Accuracy score train set : 0.8228884590586718\n",
      "Accuracy score test set  : 0.8050541516245487 \n",
      "\n",
      "Positive:  {'precision': 0.8831417624521073, 'recall': 0.4767321613236815, 'f1-score': 0.6192075218267293, 'support': 967}\n",
      "Neutral :  {'precision': 0.7887411073306526, 'recall': 0.9800153727901614, 'f1-score': 0.8740359897172236, 'support': 2602}\n",
      "Negative:  {'precision': 0.9024390243902439, 'recall': 0.3592233009708738, 'f1-score': 0.513888888888889, 'support': 309}\n",
      "\n",
      " --------------------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  3 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Decision Tree Classifier Model : \n",
      " \n",
      "Training time: 0.247996s; Prediction time: 0.008039s \n",
      "\n",
      "Accuracy score train set : 0.7823984526112185\n",
      "Accuracy score test set  : 0.7759154203197525 \n",
      "\n",
      "Positive:  {'precision': 0.9387186629526463, 'recall': 0.3485005170630817, 'f1-score': 0.5082956259426848, 'support': 967}\n",
      "Neutral :  {'precision': 0.7537204552086373, 'recall': 0.9926979246733282, 'f1-score': 0.8568585171670261, 'support': 2602}\n",
      "Negative:  {'precision': 0.967391304347826, 'recall': 0.28802588996763756, 'f1-score': 0.4438902743142144, 'support': 309}\n",
      "\n",
      " --------------------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  2 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Classification Report for k = 1 is:\n",
      "\n",
      "Training time: 0.040735s ; Prediction time: 2.544560s \n",
      "\n",
      "Accuracy score train set : 0.8084461637653128\n",
      "Accuracy score test set  : 0.776173285198556 \n",
      "\n",
      "Positive:  {'precision': 0.7779661016949152, 'recall': 0.47466390899689764, 'f1-score': 0.5895953757225433, 'support': 967}\n",
      "Neutral :  {'precision': 0.7832638666239179, 'recall': 0.9388931591083781, 'f1-score': 0.8540464953679426, 'support': 2602}\n",
      "Negative:  {'precision': 0.6390532544378699, 'recall': 0.34951456310679613, 'f1-score': 0.4518828451882846, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  2 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Classification Report for k = 3 is:\n",
      "\n",
      "Training time: 0.032002s ; Prediction time: 2.372464s \n",
      "\n",
      "Accuracy score train set : 0.7159252095422308\n",
      "Accuracy score test set  : 0.6890149561629706 \n",
      "\n",
      "Positive:  {'precision': 0.4510416666666667, 'recall': 0.8955532574974147, 'f1-score': 0.5999307239348804, 'support': 967}\n",
      "Neutral :  {'precision': 0.9266702878870179, 'recall': 0.6556495003843198, 'f1-score': 0.7679495836146749, 'support': 2602}\n",
      "Negative:  {'precision': 0.8547008547008547, 'recall': 0.32362459546925565, 'f1-score': 0.4694835680751173, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  2 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Classification Report for k = 5 is:\n",
      "\n",
      "Training time: 0.047961s ; Prediction time: 3.330191s \n",
      "\n",
      "Accuracy score train set : 0.7968407479045777\n",
      "Accuracy score test set  : 0.7851985559566786 \n",
      "\n",
      "Positive:  {'precision': 0.8226120857699805, 'recall': 0.4364012409513961, 'f1-score': 0.5702702702702703, 'support': 967}\n",
      "Neutral :  {'precision': 0.7743417023882425, 'recall': 0.971944657955419, 'f1-score': 0.8619631901840491, 'support': 2602}\n",
      "Negative:  {'precision': 0.9494949494949495, 'recall': 0.3042071197411003, 'f1-score': 0.46078431372549017, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  2 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Classification Report for k = 7 is:\n",
      "\n",
      "Training time: 0.031962s ; Prediction time: 3.377729s \n",
      "\n",
      "Accuracy score train set : 0.7943907156673115\n",
      "Accuracy score test set  : 0.7849406910778752 \n",
      "\n",
      "Positive:  {'precision': 0.8280632411067194, 'recall': 0.4332988624612203, 'f1-score': 0.5689069925322472, 'support': 967}\n",
      "Neutral :  {'precision': 0.7735042735042735, 'recall': 0.9738662567255957, 'f1-score': 0.8621980265396394, 'support': 2602}\n",
      "Negative:  {'precision': 0.9479166666666666, 'recall': 0.29449838187702265, 'f1-score': 0.4493827160493827, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  2 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Classification Report for k = 10 is:\n",
      "\n",
      "Training time: 0.032003s ; Prediction time: 3.360441s \n",
      "\n",
      "Accuracy score train set : 0.7893617021276595\n",
      "Accuracy score test set  : 0.7849406910778752 \n",
      "\n",
      "Positive:  {'precision': 0.8822222222222222, 'recall': 0.4105480868665977, 'f1-score': 0.5603387438249824, 'support': 967}\n",
      "Neutral :  {'precision': 0.767616191904048, 'recall': 0.9838585703305149, 'f1-score': 0.8623884116557183, 'support': 2602}\n",
      "Negative:  {'precision': 0.9354838709677419, 'recall': 0.2815533980582524, 'f1-score': 0.4328358208955224, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  3 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Classification Report for k = 1 is:\n",
      "\n",
      "Training time: 0.023999s ; Prediction time: 1.952000s \n",
      "\n",
      "Accuracy score train set : 0.7754996776273372\n",
      "Accuracy score test set  : 0.759927797833935 \n",
      "\n",
      "Positive:  {'precision': 0.8906666666666667, 'recall': 0.3453981385729059, 'f1-score': 0.49776453055141584, 'support': 967}\n",
      "Neutral :  {'precision': 0.7482993197278912, 'recall': 0.9723289777094543, 'f1-score': 0.8457295671068027, 'support': 2602}\n",
      "Negative:  {'precision': 0.680327868852459, 'recall': 0.2686084142394822, 'f1-score': 0.38515081206496515, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  3 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Classification Report for k = 3 is:\n",
      "\n",
      "Training time: 0.031998s ; Prediction time: 2.463243s \n",
      "\n",
      "Accuracy score train set : 0.7751128304319793\n",
      "Accuracy score test set  : 0.7705002578648789 \n",
      "\n",
      "Positive:  {'precision': 0.9297752808988764, 'recall': 0.3422957600827301, 'f1-score': 0.5003779289493575, 'support': 967}\n",
      "Neutral :  {'precision': 0.7510204081632653, 'recall': 0.9900076863950807, 'f1-score': 0.8541114058355438, 'support': 2602}\n",
      "Negative:  {'precision': 0.8804347826086957, 'recall': 0.2621359223300971, 'f1-score': 0.40399002493765584, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  3 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Classification Report for k = 5 is:\n",
      "\n",
      "Training time: 0.031996s ; Prediction time: 3.080080s \n",
      "\n",
      "Accuracy score train set : 0.7709219858156028\n",
      "Accuracy score test set  : 0.7692109334708612 \n",
      "\n",
      "Positive:  {'precision': 0.898936170212766, 'recall': 0.34953464322647365, 'f1-score': 0.5033507073715562, 'support': 967}\n",
      "Neutral :  {'precision': 0.7504378283712785, 'recall': 0.9880860876249039, 'f1-score': 0.8530192435301925, 'support': 2602}\n",
      "Negative:  {'precision': 0.9736842105263158, 'recall': 0.23948220064724918, 'f1-score': 0.38441558441558443, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  3 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Classification Report for k = 7 is:\n",
      "\n",
      "Training time: 0.031998s ; Prediction time: 2.967993s \n",
      "\n",
      "Accuracy score train set : 0.7705996131528047\n",
      "Accuracy score test set  : 0.7686952037132543 \n",
      "\n",
      "Positive:  {'precision': 0.8854166666666666, 'recall': 0.3516028955532575, 'f1-score': 0.5033308660251665, 'support': 967}\n",
      "Neutral :  {'precision': 0.7509511267193445, 'recall': 0.9861644888547272, 'f1-score': 0.8526333277953149, 'support': 2602}\n",
      "Negative:  {'precision': 0.974025974025974, 'recall': 0.24271844660194175, 'f1-score': 0.38860103626943, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Models with  3 -grams :\n",
      "\n",
      "********************** \n",
      "\n",
      "Classification Report for k = 10 is:\n",
      "\n",
      "Training time: 0.039997s ; Prediction time: 3.743998s \n",
      "\n",
      "Accuracy score train set : 0.7682785299806576\n",
      "Accuracy score test set  : 0.7684373388344508 \n",
      "\n",
      "Positive:  {'precision': 0.9136490250696379, 'recall': 0.3391933815925543, 'f1-score': 0.4947209653092006, 'support': 967}\n",
      "Neutral :  {'precision': 0.7489102005231038, 'recall': 0.990392006149116, 'f1-score': 0.8528876385901044, 'support': 2602}\n",
      "Negative:  {'precision': 0.9615384615384616, 'recall': 0.24271844660194175, 'f1-score': 0.3875968992248062, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "SupportVectorClassifier=svm.SVC(kernel='linear')\n",
    "\n",
    "LogReg2=NgramModels(Model=LogisticRegression(),txt='Logistic Regression Model : \\n ', n=2)\n",
    "LogReg3=NgramModels(Model=LogisticRegression(),txt='Logistic Regression Model : \\n ', n=3)\n",
    "\n",
    "svm2=NgramModels(Model=SupportVectorClassifier ,txt='Support Vectoer Classifier Model : \\n ', n=2)\n",
    "svm3=NgramModels(Model=SupportVectorClassifier ,txt='Support Vectoer Classifier Model : \\n ', n=3)\n",
    "\n",
    "DecTree2=NgramModels(Model=tree.DecisionTreeClassifier(),txt='Decision Tree Classifier Model : \\n ', n=2)\n",
    "DecTree3=NgramModels(Model=tree.DecisionTreeClassifier(),txt='Decision Tree Classifier Model : \\n ', n=3)\n",
    "\n",
    "KNN2=KNN_Ngram(2)\n",
    "KNN3=KNN_Ngram(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models with Tfidf Feature extraction Techniques : \n",
      "\n",
      "************************************************ \n",
      "\n",
      "Logistic Regression Model : \n",
      " \n",
      "Training time: 2.321228s; Prediction time: 0.000000s \n",
      "\n",
      "Accuracy score train set : 0.9706640876853643\n",
      "Accuracy score test set  : 0.9522949974213513 \n",
      "\n",
      "Positive:  {'precision': 0.9725877192982456, 'recall': 0.9172699069286453, 'f1-score': 0.9441192123469931, 'support': 967}\n",
      "Neutral :  {'precision': 0.9436363636363636, 'recall': 0.9973097617217525, 'f1-score': 0.9697309417040357, 'support': 2602}\n",
      "Negative:  {'precision': 0.9768518518518519, 'recall': 0.6828478964401294, 'f1-score': 0.8038095238095239, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Support Vector Classifier Model : \n",
      " \n",
      "Training time: 27.824473s; Prediction time: 4.186903s \n",
      "\n",
      "Accuracy score train set : 0.9889748549323018\n",
      "Accuracy score test set  : 0.9783393501805054 \n",
      "\n",
      "Positive:  {'precision': 0.9831223628691983, 'recall': 0.9638055842812823, 'f1-score': 0.9733681462140992, 'support': 967}\n",
      "Neutral :  {'precision': 0.977076287110109, 'recall': 0.9992313604919293, 'f1-score': 0.9880296408892266, 'support': 2602}\n",
      "Negative:  {'precision': 0.9739776951672863, 'recall': 0.8478964401294499, 'f1-score': 0.9065743944636678, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Decision Tree Classifier Model : \n",
      " \n",
      "Training time: 4.073259s; Prediction time: 0.008179s \n",
      "\n",
      "Accuracy score train set : 0.9999355254674404\n",
      "Accuracy score test set  : 0.9863331614234141 \n",
      "\n",
      "Positive:  {'precision': 0.9764344262295082, 'recall': 0.9855222337125129, 'f1-score': 0.9809572825527535, 'support': 967}\n",
      "Neutral :  {'precision': 0.9923400995787055, 'recall': 0.995772482705611, 'f1-score': 0.9940533282179167, 'support': 2602}\n",
      "Negative:  {'precision': 0.9656357388316151, 'recall': 0.9093851132686084, 'f1-score': 0.9366666666666668, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report for k = 1 is:\n",
      "\n",
      "Training time: 0.032512s ; Prediction time: 2.063442s \n",
      "\n",
      "Accuracy score train set : 0.9999355254674404\n",
      "Accuracy score test set  : 0.8705518308406395 \n",
      "\n",
      "Positive:  {'precision': 0.9191780821917809, 'recall': 0.6938986556359876, 'f1-score': 0.7908073070123748, 'support': 967}\n",
      "Neutral :  {'precision': 0.8597208035410283, 'recall': 0.9704073789392775, 'f1-score': 0.9117169164109046, 'support': 2602}\n",
      "Negative:  {'precision': 0.8530805687203792, 'recall': 0.5825242718446602, 'f1-score': 0.6923076923076923, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report for k = 3 is:\n",
      "\n",
      "Training time: 0.032001s ; Prediction time: 2.753354s \n",
      "\n",
      "Accuracy score train set : 0.8847195357833656\n",
      "Accuracy score test set  : 0.8357400722021661 \n",
      "\n",
      "Positive:  {'precision': 0.9315525876460768, 'recall': 0.5770423991726991, 'f1-score': 0.7126436781609196, 'support': 967}\n",
      "Neutral :  {'precision': 0.8146964856230032, 'recall': 0.9800153727901614, 'f1-score': 0.8897418004187021, 'support': 2602}\n",
      "Negative:  {'precision': 0.8926174496644296, 'recall': 0.43042071197411, 'f1-score': 0.5807860262008734, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report for k = 5 is:\n",
      "\n",
      "Training time: 0.032412s ; Prediction time: 3.155959s \n",
      "\n",
      "Accuracy score train set : 0.8397163120567376\n",
      "Accuracy score test set  : 0.8115007735946365 \n",
      "\n",
      "Positive:  {'precision': 0.9471544715447154, 'recall': 0.48190279214064113, 'f1-score': 0.6387936943111721, 'support': 967}\n",
      "Neutral :  {'precision': 0.7864996945632254, 'recall': 0.9896233666410453, 'f1-score': 0.8764465622872704, 'support': 2602}\n",
      "Negative:  {'precision': 0.9464285714285714, 'recall': 0.343042071197411, 'f1-score': 0.503562945368171, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report for k = 7 is:\n",
      "\n",
      "Training time: 0.032147s ; Prediction time: 3.630382s \n",
      "\n",
      "Accuracy score train set : 0.8085751128304319\n",
      "Accuracy score test set  : 0.7962867457452295 \n",
      "\n",
      "Positive:  {'precision': 0.9603729603729604, 'recall': 0.42605997931747674, 'f1-score': 0.5902578796561605, 'support': 967}\n",
      "Neutral :  {'precision': 0.7709513868177751, 'recall': 0.9934665641813989, 'f1-score': 0.8681780016792612, 'support': 2602}\n",
      "Negative:  {'precision': 0.9479166666666666, 'recall': 0.29449838187702265, 'f1-score': 0.4493827160493827, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n",
      "Classification Report for k = 10 is:\n",
      "\n",
      "Training time: 0.040683s ; Prediction time: 3.231862s \n",
      "\n",
      "Accuracy score train set : 0.8012250161186332\n",
      "Accuracy score test set  : 0.7944816915936049 \n",
      "\n",
      "Positive:  {'precision': 0.9641148325358851, 'recall': 0.41675284384694933, 'f1-score': 0.5819494584837546, 'support': 967}\n",
      "Neutral :  {'precision': 0.7691850089232599, 'recall': 0.9938508839354343, 'f1-score': 0.8672032193158954, 'support': 2602}\n",
      "Negative:  {'precision': 0.9387755102040817, 'recall': 0.2977346278317152, 'f1-score': 0.4520884520884521, 'support': 309}\n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "SupportVectorClassifier=svm.SVC(kernel='linear')\n",
    "\n",
    "print('Models with Tfidf Feature extraction Techniques : \\n')\n",
    "print('************************************************ \\n')\n",
    "\n",
    "LogReg=TFIDFModels(Model=LogisticRegression(),txt='Logistic Regression Model : \\n ')\n",
    "svm=TFIDFModels(Model=SupportVectorClassifier,txt='Support Vector Classifier Model : \\n ')\n",
    "DecTree=TFIDFModels(Model=tree.DecisionTreeClassifier(),txt='Decision Tree Classifier Model : \\n ')\n",
    "knn_tfidf=KNN_TFIDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.MultiIndex.from_product([['2-grams', '3-grams', 'TFIDF'],['Accuracy Training %','Accuracy Testing %']],names=['FeatureExtraction', 'Metric'])\n",
    "col = ['LogisticRegression', 'SupportVectorClassifier', 'DecisionTree', 'KNeighborsClassifier']\n",
    "\n",
    "Result = pd.DataFrame('*', idx, col)\n",
    "Result.LogisticRegression=['80.79','80.32','77.80','77.53','97.06','95.22']\n",
    "Result.SupportVectorClassifier=['80.73','80.42','77.80','77.74','98.89','97.83']\n",
    "Result.DecisionTree=['82.28','80.50','78.23','77.59','99.97','98.63']\n",
    "Result.KNeighborsClassifier=['80.84','77.61','77.54','75.99','99.96','87.05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>SupportVectorClassifier</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FeatureExtraction</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2-grams</th>\n",
       "      <th>Accuracy Training %</th>\n",
       "      <td>80.79</td>\n",
       "      <td>80.73</td>\n",
       "      <td>82.28</td>\n",
       "      <td>80.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy Testing %</th>\n",
       "      <td>80.32</td>\n",
       "      <td>80.42</td>\n",
       "      <td>80.50</td>\n",
       "      <td>77.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3-grams</th>\n",
       "      <th>Accuracy Training %</th>\n",
       "      <td>77.80</td>\n",
       "      <td>77.80</td>\n",
       "      <td>78.23</td>\n",
       "      <td>77.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy Testing %</th>\n",
       "      <td>77.53</td>\n",
       "      <td>77.74</td>\n",
       "      <td>77.59</td>\n",
       "      <td>75.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">TFIDF</th>\n",
       "      <th>Accuracy Training %</th>\n",
       "      <td>97.06</td>\n",
       "      <td>98.89</td>\n",
       "      <td>99.97</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy Testing %</th>\n",
       "      <td>95.22</td>\n",
       "      <td>97.83</td>\n",
       "      <td>98.63</td>\n",
       "      <td>87.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      LogisticRegression  \\\n",
       "FeatureExtraction Metric                                   \n",
       "2-grams           Accuracy Training %              80.79   \n",
       "                  Accuracy Testing %               80.32   \n",
       "3-grams           Accuracy Training %              77.80   \n",
       "                  Accuracy Testing %               77.53   \n",
       "TFIDF             Accuracy Training %              97.06   \n",
       "                  Accuracy Testing %               95.22   \n",
       "\n",
       "                                      SupportVectorClassifier DecisionTree  \\\n",
       "FeatureExtraction Metric                                                     \n",
       "2-grams           Accuracy Training %                   80.73        82.28   \n",
       "                  Accuracy Testing %                    80.42        80.50   \n",
       "3-grams           Accuracy Training %                   77.80        78.23   \n",
       "                  Accuracy Testing %                    77.74        77.59   \n",
       "TFIDF             Accuracy Training %                   98.89        99.97   \n",
       "                  Accuracy Testing %                    97.83        98.63   \n",
       "\n",
       "                                      KNeighborsClassifier  \n",
       "FeatureExtraction Metric                                    \n",
       "2-grams           Accuracy Training %                80.84  \n",
       "                  Accuracy Testing %                 77.61  \n",
       "3-grams           Accuracy Training %                77.54  \n",
       "                  Accuracy Testing %                 75.99  \n",
       "TFIDF             Accuracy Training %                99.96  \n",
       "                  Accuracy Testing %                 87.05  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result.to_csv(\"FinalResult.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
